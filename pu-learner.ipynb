{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook to show how PU learning works\n",
    "\n",
    "This notebook will show examples of PU Bagging by Roy Wright and Two Step Approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Banknote Dataset involves predicting whether a given banknote is authentic given a number of measures taken from a photograph.\n",
    "It is a binary (2-class) classification problem. The number of observations for each class is not balanced. There are 1,372 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "- Variance of Wavelet Transformed image (continuous).\n",
    "- Skewness of Wavelet Transformed image (continuous).\n",
    "- Kurtosis of Wavelet Transformed image (continuous).\n",
    "- Entropy of image (continuous).\n",
    "- Class (0 for authentic, 1 for inauthentic).\n",
    "\n",
    "The baseline performance of predicting the most prevalent class is a classification accuracy of approximately 50%.\n",
    "\n",
    "### Source\n",
    "- http://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import docopt\n",
    "import pickle\n",
    "import logging\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from baggingPU import BaggingClassifierPU\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Create place to save diagrams\n",
    "image_dir = './images/'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.mkdir(image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# https://gist.github.com/zachguo/10296432\n",
    "#\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]) + 4\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % 'pred_' + label, end=\" \")\n",
    "    print()\n",
    "\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % 'true_' + label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            if cell:\n",
    "                print(cell, end=\" \")\n",
    "        print()\n",
    "\n",
    "def plot_bar(df, col, rgb):\n",
    "    tmp_df = df.copy()\n",
    "    tmp_df[col] = tmp_df[col].map({0: 'Negative', 1: 'Positive'})\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    tmp = tmp_df[col].value_counts()\n",
    "    tmp.plot.bar(ax=ax,rot=0, color=rgb)\n",
    "    plt.legend(loc='upper left')\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(os.path.join(image_dir, '{}_bar.jpg'.format(col)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    762\n",
      "1    610\n",
      "Name: authentic, dtype: int64\n",
      "Has null values False\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('data_banknote_authentication.txt', \n",
    "                     names=['variance', 'skewness', 'kurtosis', 'entropy', 'authentic'])\n",
    "print(df_raw.authentic.value_counts())\n",
    "print('Has null values', df_raw.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>authentic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  kurtosis  entropy  authentic\n",
       "0   3.62160    8.6661   -2.8073 -0.44699          0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210          0\n",
       "2   3.86600   -2.6383    1.9242  0.10645          0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440          0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace some positive cases with zeros \n",
    "\n",
    "For example sake, we will replicate the scenario where you have positive classes that are mislabeled as negative <br>\n",
    "Essentially, we are gonna hide some of the positives to see how well the models retrieve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_undersampling(tmp_df, TARGET_LABEL):\n",
    "    df_majority = tmp_df[tmp_df[TARGET_LABEL] == 0]\n",
    "    df_minority = tmp_df[tmp_df[TARGET_LABEL] == 1]\n",
    "\n",
    "    # Downsample majority class\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                       replace=False,              # sample without replacement\n",
    "                                       n_samples=len(df_minority), # to match minority class\n",
    "                                       random_state=None)        # reproducible results\n",
    "    # Combine minority class with downsampled majority class\n",
    "    df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "    print(\"Undersampling complete!\")\n",
    "    print(df_downsampled[TARGET_LABEL].value_counts())\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling complete!\n",
      "1    610\n",
      "0    610\n",
      "Name: authentic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_downsampled = random_undersampling(df_raw, 'authentic')\n",
    "df_downsampled = df_downsampled.sample(frac=1) #Shuffle the data\n",
    "df_downsampled = df_downsampled.reset_index() #Reset the index\n",
    "df_downsampled = df_downsampled.drop(columns=['index']) # Drop original index col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>authentic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.27331</td>\n",
       "      <td>4.8773</td>\n",
       "      <td>-4.91940</td>\n",
       "      <td>-5.81980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.61040</td>\n",
       "      <td>8.0081</td>\n",
       "      <td>-0.23592</td>\n",
       "      <td>-1.76080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.24030</td>\n",
       "      <td>-3.7082</td>\n",
       "      <td>5.28040</td>\n",
       "      <td>0.41291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.48080</td>\n",
       "      <td>8.1819</td>\n",
       "      <td>0.27818</td>\n",
       "      <td>-5.03230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.07130</td>\n",
       "      <td>10.4023</td>\n",
       "      <td>-4.17220</td>\n",
       "      <td>-4.75820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  kurtosis  entropy  authentic\n",
       "0   0.27331    4.8773  -4.91940 -5.81980          1\n",
       "1   2.61040    8.0081  -0.23592 -1.76080          0\n",
       "2   3.24030   -3.7082   5.28040  0.41291          0\n",
       "3  -5.48080    8.1819   0.27818 -5.03230          1\n",
       "4   4.07130   10.4023  -4.17220 -4.75820          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lets make some negatives out of the positives by unlabeling a certain number of data points\n",
    "\n",
    "'''\n",
    "# Make a new df because we will need that for later\n",
    "df = df_downsampled.copy()\n",
    "\n",
    "#Separate cols from label\n",
    "NON_LBL = [c for c in df.columns if c != 'authentic']\n",
    "X = df[NON_LBL]\n",
    "y = df['authentic']\n",
    "\n",
    "# Save the original labels and indices\n",
    "y_orig = y.copy()\n",
    "original_idx = np.where(df_downsampled.authentic == 1)\n",
    "\n",
    "# Here we are imputing 300 positives as negative\n",
    "hidden_size = 300\n",
    "y.loc[\n",
    "    np.random.choice(\n",
    "        y[y == 1].index, \n",
    "        replace = False, \n",
    "        size = hidden_size\n",
    "    )\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    910\n",
       "1    310\n",
       "Name: authentic, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have 910 unreliable \"negatives\" and 310 true positives\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1220 samples and 4 features\n",
      "- 610 positive out of 1220 total before hiding labels\n",
      "- 310 positive out of 1220 total after hiding labels\n"
     ]
    }
   ],
   "source": [
    "print('- %d samples and %d features' % (X.shape))\n",
    "print('- %d positive out of %d total before hiding labels' % (sum(df_downsampled.authentic), len(df_downsampled.authentic)))\n",
    "print('- %d positive out of %d total after hiding labels' % (sum(y), len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training standard random forest model ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Training standard random forest model ...')\n",
    "\n",
    "#First random forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators = 50,  \n",
    "    n_jobs = -1           \n",
    ")\n",
    "rf.fit(X, y)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Standard Random Forest ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative        610.0          0.0 \n",
      "           true_positive        301.0        309.0 \n",
      "None\n",
      "\n",
      "Precision:  1.0\n",
      "Recall:  0.5065573770491804\n",
      "Accuracy:  0.7532786885245901\n"
     ]
    }
   ],
   "source": [
    "print('---- {} ----'.format('Standard Random Forest'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, rf.predict(X)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, rf.predict(X)))\n",
    "print('Recall: ', recall_score(y_orig, rf.predict(X)))\n",
    "print('Accuracy: ', accuracy_score(y_orig, rf.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the standars random forest didn't do very for predicting the hidden positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bagging classifier...\n",
      "Done!\n",
      "Time: 3.3925690629985183\n"
     ]
    }
   ],
   "source": [
    "print('Training bagging classifier...')\n",
    "pu_start = time.perf_counter()\n",
    "bc = BaggingClassifierPU(RandomForestClassifier(n_estimators=20, random_state=2019), \n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  # Each training sample will be balanced \n",
    "                        )\n",
    "bc.fit(X, y)\n",
    "pu_end = time.perf_counter()\n",
    "print('Done!')\n",
    "print('Time:', pu_end - pu_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- PU Bagging ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative        610.0          0.0 \n",
      "           true_positive         39.0        571.0 \n",
      "None\n",
      "\n",
      "Precision:  1.0\n",
      "Recall:  0.9360655737704918\n",
      "Accuracy:  0.9680327868852459\n"
     ]
    }
   ],
   "source": [
    "print('---- {} ----'.format('PU Bagging'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, bc.predict(X)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, bc.predict(X)))\n",
    "print('Recall: ', recall_score(y_orig, bc.predict(X)))\n",
    "print('Accuracy: ', accuracy_score(y_orig, bc.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its clear that PU Bagging is doing significantly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Step Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting unlabaled to -1 and positive to 1...\n",
      "Getting probabilities for all positive cases...\n",
      "Creating range of scores for probabilities of positive cases...\n",
      "Relabelling unknowns in score range as positive...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create a new target vector, with 1 for positive, -1 for unlabeled, and \n",
    "# 0 for \"reliable negative\" (there are no reliable negatives to start with)\n",
    "print('Converting unlabaled to -1 and positive to 1...')\n",
    "ys = 2 * y - 1\n",
    "\n",
    "print('Getting probabilities for all positive cases...')\n",
    "# Get the scores from before\n",
    "pred = rf.predict_proba(X)[:,1]\n",
    "\n",
    "print('Creating range of scores for probabilities of positive cases...')\n",
    "# Find the range of scores given to positive data points\n",
    "range_pos = [min(pred * (ys > 0)), max(pred * (ys > 0))]\n",
    "\n",
    "print('Relabelling unknowns in score range as positive...')\n",
    "# STEP 1\n",
    "# If any unlabeled point has a score above all known positives, \n",
    "# or below all known positives, label it accordingly\n",
    "iP_new = ys[(ys < 0) & (pred >= range_pos[1])].index\n",
    "iN_new = ys[(ys < 0) & (pred <= range_pos[0])].index\n",
    "ys.loc[iP_new] = 1\n",
    "ys.loc[iN_new] = 0\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing second random forest for two-step...\n"
     ]
    }
   ],
   "source": [
    "print('Initializing second random forest for two-step...')\n",
    "tsa = RandomForestClassifier(n_estimators = 50, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Step 1 labeled 0 new positives and 541 new negatives.\n",
      "Doing step 2... Iteration:  1\n",
      "Step 1 labeled 0 new positives and 51 new negatives.\n",
      "Doing step 2... Iteration:  2\n",
      "Step 1 labeled 0 new positives and 9 new negatives.\n",
      "Doing step 2... Iteration:  3\n",
      "Step 1 labeled 0 new positives and 5 new negatives.\n",
      "Doing step 2... Iteration:  4\n",
      "Step 1 labeled 0 new positives and 2 new negatives.\n",
      "Doing step 2... Iteration:  5\n",
      "Step 1 labeled 0 new positives and 4 new negatives.\n",
      "Doing step 2... Iteration:  6\n",
      "Step 1 labeled 0 new positives and 2 new negatives.\n",
      "Doing step 2... Iteration:  7\n",
      "Step 1 labeled 0 new positives and 5 new negatives.\n",
      "Doing step 2... Iteration:  8\n",
      "Step 1 labeled 0 new positives and 1 new negatives.\n",
      "Doing step 2... Iteration:  9\n",
      "Done!\n",
      "Time: 2.227621693000401\n"
     ]
    }
   ],
   "source": [
    "tsa_start = time.perf_counter()\n",
    "for i in range(15):\n",
    "    print('Iteration: ', i)\n",
    "    # If step 1 didn't find new labels, we're done\n",
    "    if len(iP_new) + len(iN_new) == 0 and i > 0:\n",
    "        break\n",
    "    \n",
    "    print('Step 1 labeled %d new positives and %d new negatives.' % (len(iP_new), len(iN_new)))\n",
    "    print('Doing step 2... ', end = '')\n",
    "    \n",
    "    # STEP 2\n",
    "    # Retrain on new labels and get new scores\n",
    "    tsa.fit(X, ys)\n",
    "    pred = tsa.predict_proba(X)[:,-1]\n",
    "    \n",
    "    # Find the range of scores given to positive data points\n",
    "    range_P = [min(pred * (ys > 0)), max(pred * (ys > 0))]\n",
    "    \n",
    "    # Repeat step 1\n",
    "    iP_new = ys[(ys < 0) & (pred >= range_P[1])].index\n",
    "    iN_new = ys[(ys < 0) & (pred <= range_P[0])].index\n",
    "    ys.loc[iP_new] = 1\n",
    "    ys.loc[iN_new] = 0\n",
    "    \n",
    "tsa_end = time.perf_counter()\n",
    "\n",
    "print('Done!')\n",
    "print('Time:', tsa_end - tsa_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TSA ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative        610.0          0.0 \n",
      "           true_positive        300.0        310.0 \n",
      "None\n",
      "\n",
      "Precision:  1.0\n",
      "Recall:  0.5081967213114754\n",
      "Accuracy:  0.7540983606557377\n"
     ]
    }
   ],
   "source": [
    "print('---- {} ----'.format('TSA'))\n",
    "y_hat_val = tsa.predict(X)\n",
    "y_hat_val = [x if ((x==0) or (x==1)) else 0 for x in y_hat_val]\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, y_hat_val), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, y_hat_val))\n",
    "print('Recall: ',    recall_score(y_orig, y_hat_val))\n",
    "print('Accuracy: ',  accuracy_score(y_orig, y_hat_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this case, the TSA model did not perform as well as the PU Bagging model, but it is still better than having 910 unreliable negatives and 310 positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we have\n",
    "- The original 610/610 negative and positive labels\n",
    "- the 910/310 imbalanced labels\n",
    "- and the predicted classes from the standard classifier\n",
    "'''\n",
    "#Use this for plotting\n",
    "results = pd.DataFrame({\n",
    "    'truth'       : y_orig,             # True labels\n",
    "    'hidden_label': y,                  # Labels shown to models\n",
    "    'output_rf'   : rf.predict(X),       # Random forest's scores\n",
    "    'output_bag'  : bc.predict(X),      # Random forest's scores\n",
    "    'output_tsa'  : y_hat_val          # Random forest's scores\n",
    "}, columns = ['truth', 'hidden_label', 'output_rf', 'output_bag', 'output_tsa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, rgb in zip(results.columns, ['tomato', 'mediumpurple', 'lightblue', 'green', 'pink']):\n",
    "    plot_bar(results, col, rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python36864bitanaconda3virtualenv59e2ff4492e04649af7e0fd703909eac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
